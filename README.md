# ğŸ§© ScratchFormer

**ScratchFormer** is a Transformer neural network built **entirely from scratch** using **NumPy**.  
This project helps you deeply understand how modern architectures like GPT and BERT actually work â€” by implementing every part manually, from attention to embeddings.

---

## ğŸš€ Features
- âœ… Pure **NumPy** implementation (no deep learning frameworks)
- ğŸ§  Full **Encoderâ€“Decoder Transformer** architecture
- ğŸ” Implements:
  - Scaled Dot-Product & Multi-Head Attention  
  - Positional Encoding (sinusoidal)  
  - Feed Forward Networks (GELU activation)  
  - Layer Normalization & Residual Connections
- ğŸ§© Modular and easy to extend
- ğŸ’¡ Educational, readable, and well-documented
- ğŸ§ª Includes toy training example (copy / translation task)

---

## ğŸ—ï¸ Project Structure
